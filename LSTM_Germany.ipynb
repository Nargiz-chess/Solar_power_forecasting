{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Germany.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEyn0c/Xp0IfM3QMypeUWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nargiz-chess/Solar_forecasting/blob/main/LSTM_Germany.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OQmGdBsNG4f",
        "outputId": "d3fda90b-7810-4528-86fd-d57abb8eca0a"
      },
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# multivariate multi-step encoder-decoder lstm\n",
        "from math import sqrt\n",
        "from numpy import split\n",
        "from numpy import array\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayfo_fBqNO3O"
      },
      "source": [
        "path1 = '/content/drive/MyDrive/Master_thesis/Datasets/Gerdata_clean.csv'\n",
        "path2 = '/content/drive/MyDrive/Master_thesis/Datasets/irradiance.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlNiwrvBOZaT",
        "outputId": "d9a1021b-6787-4062-93f2-ab8f99fbb503"
      },
      "source": [
        "df1 = read_csv(path1, header =0, index_col=0) \n",
        "\n",
        "df.head()\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DE_KN_industrial1_pv_1', 'DE_KN_industrial1_pv_2',\n",
              "       'DE_KN_industrial2_pv', 'DE_KN_industrial3_pv_facade',\n",
              "       'DE_KN_industrial3_pv_roof', 'DE_KN_residential1_pv',\n",
              "       'DE_KN_residential3_pv', 'DE_KN_residential4_pv',\n",
              "       'DE_KN_residential6_pv'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL4zzjCkSOnw",
        "outputId": "cf8d15fd-84ba-4f52-e307-fad874d43e01"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6588, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoYCmjxzO34-",
        "outputId": "eb8b1bc8-d795-4393-f2e6-c57c40d5c358"
      },
      "source": [
        "array = df.values\n",
        "\n",
        "Gerdata = array.reshape(array.shape[0]*array.shape[1], order=\"F\")\n",
        "print(Gerdata.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59292,)\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "4kQOstIHRfVH",
        "outputId": "13fe640f-78d2-4d2b-9a8a-8c79ba6c05f6"
      },
      "source": [
        "df2=read_csv(path2, header =0, index_col=0) \n",
        "df2.head()\n",
        "\n",
        "df2=df2.drop(\"local_time\", axis=1)\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>radiation_surface</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>local_time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-02-01 05:00</th>\n",
              "      <td>2016-02-01 04:00:00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-02-01 06:00</th>\n",
              "      <td>2016-02-01 05:00:00</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-02-01 07:00</th>\n",
              "      <td>2016-02-01 06:00:00</td>\n",
              "      <td>0.467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-02-01 08:00</th>\n",
              "      <td>2016-02-01 07:00:00</td>\n",
              "      <td>31.309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-02-01 09:00</th>\n",
              "      <td>2016-02-01 08:00:00</td>\n",
              "      <td>112.503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 time  radiation_surface\n",
              "local_time                                              \n",
              "2016-02-01 05:00  2016-02-01 04:00:00              0.000\n",
              "2016-02-01 06:00  2016-02-01 05:00:00              0.000\n",
              "2016-02-01 07:00  2016-02-01 06:00:00              0.467\n",
              "2016-02-01 08:00  2016-02-01 07:00:00             31.309\n",
              "2016-02-01 09:00  2016-02-01 08:00:00            112.503"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5UmMy5GSE4P",
        "outputId": "95009682-4a50-4b1d-f27a-ac3f76ce1c23"
      },
      "source": [
        "array2 = df2.values\n",
        "\n",
        "print(array2)\n",
        "print(array2.shape)\n",
        "\n",
        "weath_data = array2.reshape(array2.shape[0]*array2.shape[1])\n",
        "\n",
        "print(weath_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   ]\n",
            " [0.   ]\n",
            " [0.467]\n",
            " ...\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]]\n",
            "(6588, 1)\n",
            "[0.    0.    0.467 ... 0.    0.    0.   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOir_HI4SiRB"
      },
      "source": [
        "len(df.columns)\n",
        "\n",
        "#stacking irradiance 9 times to match with each house in the datset\n",
        "weath_data = np.tile(weath_data,9)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikx6gUL-TPHC",
        "outputId": "77784720-6c7d-474f-b6f2-2ee167381899"
      },
      "source": [
        "weath_data.shape #validate\" same length as the Gerdata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59292,)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0ebkyXfTiSo",
        "outputId": "b48e7168-bfce-464c-f053-bb17a731d4b8"
      },
      "source": [
        "data= np.column_stack((Gerdata,weath_data))\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59292, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrpdduG-4mdT"
      },
      "source": [
        "# with open (\"/content/drive/MyDrive/Master_thesis/Datasets/Data_to_supervised.npy\", \"wb\") as a:\n",
        "#    np.save(a,data_csv)\n",
        "\n",
        "# array = np.load(\"/content/drive/MyDrive/Master_thesis/Datasets/Data_to_supervised.npy\")\n",
        "\n",
        "#Save the data that is in the supervised time series format\n",
        "np.savetxt(\"/content/drive/MyDrive/Master_thesis/Datasets/Data_to_supervised.npy\", data) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_PpQ9H4Hy5Z"
      },
      "source": [
        "data=np.loadtxt(\"/content/drive/MyDrive/Master_thesis/Datasets/Data_to_supervised.npy\")\n",
        "np.shape(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "d-TaWfGnVtYw",
        "outputId": "c2e266e1-e04c-46d6-8e14-83ed11968846"
      },
      "source": [
        "# split the dataset into train/test sets & scale\n",
        "\n",
        "def split_data(data=data):\n",
        "  # split \n",
        "  train, test = data[:-18], data[-18:]   \n",
        "  return train,test\n",
        "   \n",
        "def scaled(scaler_name=MinMaxScaler):\n",
        "  scaler = scaler_name()\n",
        "  train,test = split_data()\n",
        "  scaled_train =  scaler.fit_transform(train)\n",
        "  scaled_test= scaler.transform(test)\n",
        "  return scaled_train, scaled_test, scaler\n",
        "\n",
        "# restructure into windows\t\n",
        "def restructured_3D_data():\n",
        "  train,test,_ =  scaled()\n",
        "  train = array(split(train, len(train)/18))\n",
        "  test = array(split(test, len(test)/18))\n",
        "  return train, test\n",
        "\n",
        "\n",
        "# evaluate  forecasts against expected values\n",
        "def evaluate_forecasts(actual, predicted):\n",
        "\tscores = list()\n",
        "\t# calculate an RMSE score for each day\n",
        "\tfor i in range(actual.shape[1]):\n",
        "\t\t# calculate mse\n",
        "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
        "\t\t# calculate rmse\n",
        "\t\trmse = sqrt(mse)\n",
        "\t\t# store\n",
        "\t\tscores.append(rmse)\n",
        "\t# calculate overall RMSE\n",
        "\ts = 0\n",
        "\tfor row in range(actual.shape[0]):\n",
        "\t\tfor col in range(actual.shape[1]):\n",
        "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
        "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
        "\treturn score, scores\n",
        " \n",
        "# summarize scores\n",
        "def summarize_scores(name, score, scores):\n",
        "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
        "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
        " \n",
        "# convert history into inputs and outputs\n",
        "def to_supervised(train, n_input, n_out=18):\n",
        "\t# flatten data\n",
        "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
        "\tX, y = list(), list()\n",
        "\tin_start = 0\n",
        "\t# step over the entire history one time step at a time\n",
        "\tfor _ in range(len(data)):\n",
        "\t\t# define the end of the input sequence\n",
        "\t\tin_end = in_start + n_input\n",
        "\t\tout_end = in_end + n_out\n",
        "\t\t# ensure we have enough data for this instance\n",
        "\t\tif out_end <= len(data):\n",
        "\t\t\tX.append(data[in_start:in_end, :])\n",
        "\t\t\ty.append(data[in_end:out_end, 0])\n",
        "\t\t# move along one time step\n",
        "\t\tin_start += 1\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# train the model\n",
        "def build_model(train, n_input):\n",
        "\t# prepare data\n",
        "\ttrain_x, train_y = to_supervised(train, n_input)\n",
        "\t# define parameters\n",
        "\tverbose, epochs, batch_size = 1, 20, 17\n",
        "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
        "\t# reshape output into [samples, timesteps, features]\n",
        "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(100, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\tmodel.add(RepeatVector(n_outputs))\n",
        "\tmodel.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(50, activation='relu')))\n",
        "\tmodel.add(TimeDistributed(Dense(1)))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit network\n",
        "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\treturn model\n",
        " \n",
        "# make a forecast\n",
        "def forecast(model, history, n_input):\n",
        "\t# flatten data\n",
        "\tdata = array(history)\n",
        "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
        "\t# retrieve last observations for input data\n",
        "\tinput_x = data[-n_input:, :]\n",
        "\t# reshape into [1, n_input, n]\n",
        "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
        "\t# forecast the next time steps\n",
        "\tyhat = model.predict(input_x, verbose=0)\n",
        "\t# we only want the vector forecast\n",
        "\tyhat = yhat[0]\n",
        "\treturn yhat\n",
        " \n",
        "# evaluate a single model\n",
        "def evaluate_model(train, test, n_input):\n",
        "\t# fit model\n",
        "  model = build_model(train, n_input)\n",
        "\t# history is a list of weekly data\n",
        "  history = [x for x in train]\n",
        "\t# walk-forward validation over each week\n",
        "  predictions = list()\n",
        "  for i in range(len(test)):\n",
        "\t\t# predict the week\n",
        "    yhat_sequence = forecast(model, history, n_input)\n",
        "\t\t# store the predictions\n",
        "    predictions.append(yhat_sequence)\n",
        "\t\t# get real observation and add to history for predicting the next week\n",
        "    history.append(test[i, :])\n",
        "\t# evaluate predictions days for each week\n",
        "  predictions = array(predictions)\n",
        "  score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
        "  return score, scores, predictions\n",
        "\n",
        "def inverse_predictions(prediction_array, scaler_name = MinMaxScaler):\n",
        "  train, test = split_data()\n",
        "  scaler= scaler_name()\n",
        "  PV_data = np.reshape(test[:,0], (15,1))\n",
        "  predictions = np.reshape(prediction_array,(15,1))\n",
        "  test_PV_col = scaler.fit_transform(PV_data)\n",
        "  prediction_array = scaler.inverse_transform(predictions)\n",
        "  return prediction_array\n",
        "\n",
        "# split into train and test & scale\n",
        "train, test  = restructured_3D_data()\n",
        "# evaluate model and get scores\n",
        "n_input =  18\n",
        "score, scores,scaled_predictions = evaluate_model(train, test, n_input)\n",
        "\n",
        "# summarize scores\n",
        "summarize_scores('lstm', score, scores)\n",
        "print(summarize_scores)\n",
        "\n",
        "# predictions = inverse_predictions(scaled_predictions)\n",
        "# print(predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3485/3485 [==============================] - 81s 23ms/step - loss: nan\n",
            "Epoch 2/20\n",
            " 233/3485 [=>............................] - ETA: 1:11 - loss: nan"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-64d04758e7ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# evaluate model and get scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mn_input\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;36m18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaled_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;31m# summarize scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-64d04758e7ea>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(train, test, n_input)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;31m# history is a list of weekly data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-64d04758e7ea>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(train, n_input)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}